# 面试讲解稿：script.md

(面试官您好，我叫 [你的名字]，今天我将为您介绍我独立设计和开发的一个项目：一个基于RAG和知识图谱的医疗问答系统。)

### **开场与项目概述 (大约 1 分钟)**

面试官您好。今天我想向您展示我负责的一个项目：**一个基于知识图谱和大型语言模型的医疗问答系统**。

这个项目的初衷是为了解决当前大模型在垂直领域，尤其是医疗领域，存在的“幻觉”和事实性错误问题。当用户咨询具体的医疗建议时，通用大模型可能会提供不准确甚至危险的信息。

我的核心目标是，将大模型的语言能力与结构化、高精度的知识图谱相结合，构建一个既能理解用户自然语言提问，又能提供精准、可靠医疗信息的问答机器人。简单来说，就是为大模型装上一个“事实核查器”，确保它在医疗场景下的回答既专业又安全。

### **技术架构与方案设计 (大约 4 分钟)**

为了实现这个目标，我设计了一套完整的RAG（检索增强生成）技术流程。

**整体数据流**是这样的：
1.  首先，用户通过 **Streamlit** 构建的前端界面输入问题，比如“高血压患者在饮食上要注意什么？”。
2.  后端接收到问题后，会进入我的**第一个核心模块：命名实体识别（NER）**。这个模块会从问题中精准地抽取出医疗实体，比如“高血压”。
3.  接着，**第二个核心模块——意图识别**，会判断用户的查询意图。在这个例子里，意图就是“查询疾病的忌吃食物”。
4.  有了“高血压”这个实体和“忌吃”这个意图，系统会自动生成一条 **Cypher 查询语句**，发送到 **Neo4j 知识图谱**中进行检索。
5.  知识图谱返回精确的外部知识，比如“高血压患者应避免高盐、高脂肪食物”。
6.  最后，这些检索到的知识会连同原始问题一起，被打包成一个增强的 Prompt，发送给**大语言模型（如 Llama 或千问）**，由它生成最终的、流畅且专业的回答。

**在技术选型上**，我主要基于以下考虑：
* **知识图谱 vs. 向量数据库**: 传统的RAG多采用向量库进行语义相似度检索，但在医疗领域，知识的精确性至关重要。比如“推荐药品”和“常用药品”是两种不同的关系。知识图谱能够捕捉这种精确的、结构化的关系，所以我选择了 **Neo4j** 来构建包含8大类实体、11种关系的医疗知识库，确保了检索结果的高精度。

* **NER模型**: 为了从用户问题中准确识别实体，我采用了 **RoBERTa-wwm-ext** 模型，并在其后接了一个Bi-LSTM层进行序列标注。RoBERTa对中文的理解能力很强，这为后续的精准查询打下了坚实基础。

* **意图识别方案**: 对于意图识别，我对比了三种方案：规则匹配、训练分类模型和提示工程。规则匹配泛化能力差；训练模型需要大量标注数据，成本高。因此，我最终选择了**基于大模型的提示工程**。我设计了包含上下文学习（In-Context Learning）和思维链（Chain of Thought）的 Prompt，让大模型自身来理解用户意图。这不仅免去了繁琐的数据标注，而且在测试中表现出了极高的准确率，甚至能处理一些多意图的复杂查询

  

*   **前端框架**: 我选择了 **Streamlit**，因为它能让我用纯 Python 快速搭建一个功能完善、交互友好的Web界面，非常适合快速原型验证和项目展示。

### **我的角色与具体贡献 (大约 3 分钟)**

在这个项目中，我承担了从0到1的全部核心开发工作。我的具体贡献主要集中在以下几个方面：

1. **主导了KG-RAG架构的设计与实现**：我独立完成了整个技术方案的选型与落地。最大的创新点在于，我没有沿用传统的向量RAG，而是创造性地引入知识图谱，解决了医疗场景下对信息精确性的高要求。我还编写了`build_up_graph.py`脚本，将超过4万个实体和31万条关系的高质量数据导入Neo4j图数据库。

2. **构建并优化了NER模块**：这是项目成功的关键一步。首先，我编写了`ner_data.py`脚本，通过规则匹配的方式，**从零开始构建了一份高质量的NER标注数据集**。更重要的是，为了提升模型性能，我设计并实施了**三种数据增强策略**：实体替换、实体掩码和实体拼接。通过这些优化，我将RoBERTa模型的F1值从 **96.77% 提升到了 97.40%**，显著增强了实体识别的准确性和鲁棒性。

3. **创新性地应用提示工程解决意图识别**：为了降本增效，我没有选择训练分类模型，而是负责设计了一套高效的 **Prompt Engineering** 方案。我将用户的意图归纳为16种，并巧妙地利用大模型的上下文学习能力，让它直接进行意图分类。这个方案不仅效果好，还为项目节省了大量的人工标注成本。

   

4. **完成了整个系统的端到端开发与部署**：我使用 **Streamlit** 独立开发了完整的前端应用，包括`login.py`和`webui.py`。我实现了用户注册登录、管理员后台、多窗口对话以及动态切换后端大模型等功能，将所有后端模块无缝集成，最终交付了一个可交互、高可用的产品原型。

### **项目成果与总结反思 (大约 1-2 分钟)**

通过这个项目，我成功验证了知识图谱增强RAG在垂直领域的可行性。
*   **从成果上看**：系统的核心指标——**NER准确率达到了97.4%**，保证了后续流程的有效性。相比直接使用通用大模型，我的系统在回答的**事实准确性上有了质的飞跃**，基本消除了“幻觉”现象。
*   **从个人成长上看**：我不仅深化了对RAG、知识图谱和NER等技术的理解，更锻炼了**系统设计、技术选型和端到端项目交付**的全栈能力。特别是数据增强和Prompt Engineering的实践，让我对如何“用好”大模型有了更深的体会。

当然，项目还有可优化的空间。目前我的意图识别和Cypher查询是解耦的，未来我计划探索 **NL2Cypher** 技术，即训练一个模型直接将用户问题翻译成Cypher查询语句，就像我在`finetune_demo`中尝试的那样。这将让系统能够理解更宽泛、更复杂的查询，进一步释放知识图谱的潜力。

我的介绍就到这里，谢谢各位面试官。